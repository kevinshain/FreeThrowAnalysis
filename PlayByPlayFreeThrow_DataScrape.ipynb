{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "import bs4\n",
    "import psycopg2\n",
    "import sys\n",
    "sys.path.append('/Users/kshain/Documents/Git')\n",
    "from progressbar import ProgressBar\n",
    "import sqlalchemy\n",
    "import pandas.io.sql as psql\n",
    "import time\n",
    "import re\n",
    "import datetime\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play-by-play Data Scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* [Connecting to PostgreSQL](#Connecting-to-PostgreSQL)\n",
    "* [Scraping Game Data](#Scraping-Game-Data)\n",
    "    * [Adding a season column](#Adding-a-season-column)\n",
    "* [Scraping Play-by-play Data](#Scraping-Play-by-play-Data)\n",
    "    * [Adding Year-to-date Percentage](#Adding-Year-to-date-Percentage)\n",
    "    * [Adding Score ifferential](#Adding-Score-Differential)\n",
    "* [Scraping Season Totals](#Scraping-Season-Totals)\n",
    "    * [Adding Career-to-date](#Adding-Career-to-date)\n",
    "    * [Casting to Proper Data Types](#Casting-to-Proper-Data-Types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I am going to create a PostgreSQL database to store the data as it is scraped and processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I made the actual database by simply executing `createdb freethrows` in the bash terminal. To make the connection, I will use both `psycopg2` and `sqlalchemy` since each package has some useful functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = None\n",
    "\n",
    "try:\n",
    "    conn_string = \"host='localhost',database='freethrows', user='kshain'\"\n",
    "    print('Connecting to database\\n ->',conn_string)\n",
    "    conn = psycopg2.connect(host='localhost',database='freethrows', user='kshain') \n",
    "    cur = conn.cursor()\n",
    "    print('Connected!\\n')            \n",
    "\n",
    "except psycopg2.DatabaseError:\n",
    "    print ('Error')  \n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine('postgresql://kshain@localhost:5432/freethrows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Game Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll start by going through all 66 seasons for which there is game data and scrape the data into the table `games`. I'm using the `BeautifulSoup` package which nicely organizes html for scraping. All of the `if` statements just make sure the correct field goes to the correct list. I make the list into a Pandas dataframe because `sqlalchemy` makes it really easy to go from dataframe to SQL table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pbar = ProgressBar.ProgressBar(66) \n",
    "for year in range(1950,2015+1):\n",
    "    urlstring = 'http://www.basketball-reference.com/leagues/NBA_'+str(year)+'_games.html'\n",
    "    source = urllib.request.urlopen(urlstring)\n",
    "    source = source.read()\n",
    "    soup = bs4.BeautifulSoup(source, 'lxml')\n",
    "    tds = soup.find_all('td',attrs={'align':True})\n",
    "    # initialize lists\n",
    "    date = []\n",
    "    gameid = []\n",
    "    starttime = []\n",
    "    teamv = []\n",
    "    scorev = []\n",
    "    teamh = []\n",
    "    scoreh = []\n",
    "    ot = []\n",
    "    \n",
    "    # scrape one year\n",
    "    for i,row in enumerate(tds):\n",
    "        if i%9==0:\n",
    "            date.append(time.strftime('%Y-%m-%d',time.strptime(str(row.find('a').contents[0]), '%a, %b %d, %Y')))\n",
    "            gameid.append(row['csk'])\n",
    "        if i%9==1:\n",
    "            try:\n",
    "                starttime.append(row.contents[0])\n",
    "            except:\n",
    "                starttime.append('')\n",
    "        if i%9==3:\n",
    "            teamv.append(row.find('a').contents[0])\n",
    "        if i%9==4:\n",
    "            scorev.append(int(row.contents[0]))\n",
    "        if i%9==5:\n",
    "            teamh.append(row.find('a').contents[0])\n",
    "        if i%9==6:\n",
    "            scoreh.append(int(row.contents[0]))\n",
    "        if i%9==7:\n",
    "            ot.append(row.text)\n",
    "    data = {'date':date,'gameid':gameid,'starttime':starttime,'teamv':teamv,'scorev':scorev,'teamh':teamh,'scoreh':scoreh,'ot':ot}\n",
    "    \n",
    "    #construct dataframe for games from one year\n",
    "    gamesOneYear = pd.DataFrame(data,columns=['date','gameid','starttime','teamv','scorev','teamh','scoreh','ot'])\n",
    "    \n",
    "    gamesOneYear.to_sql('games',engine,if_exists='append')\n",
    "    pbar.increment()\n",
    "pbar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because I will use it in scraping play-by-play data, I want to immediately cast the date into a `datetime` type variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"ALTER TABLE games ALTER COLUMN date TYPE DATE using to_date(date, 'YYYY-MM-DD');\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a season column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of extracting the year from the date frequently, I will encode that data separately in the `season` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT CAST(CASE WHEN EXTRACT(month FROM date)>7 THEN (EXTRACT(year FROM date)+1) ELSE (EXTRACT(year FROM Date)) END AS integer) FROM games\")\n",
    "seasondf = pd.DataFrame(cur.fetchall(), columns=['season'])\n",
    "allgamesdf = psql.read_sql(\"SELECT * FROM games\", conn)\n",
    "allgamesdf = allgamesdf.join(seasondf)\n",
    "allgamesdf.to_sql('allgames',engine,if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Play-by-play Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This contains the brunt of the scraping necessary for the more sophisticated models in the `PlayByPlayFreeThrow_DataScrape` notebook. I use the `gameid`'s from the last section to iterate through all the games with play-by-play data (2001 to present). Be aware that execution of this code will take a few hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT gameid FROM games WHERE EXTRACT(YEAR FROM date)>=2001\")\n",
    "gameids = cur.fetchall()\n",
    "print('running')\n",
    "pbar2 = ProgressBar.ProgressBar(len(gameids), finestep=True)\n",
    "\n",
    "for j,thisgameid in enumerate(gameids):\n",
    "    \n",
    "    # Data to collect for each free throw\n",
    "    gameid = []\n",
    "    gametime = []\n",
    "    player = []\n",
    "    playerid = []\n",
    "    team = []\n",
    "    teamha = []\n",
    "    opponent = []\n",
    "    scorea = []\n",
    "    scoreh = []\n",
    "    result = []\n",
    "    ftnumber = []\n",
    "    tech = []\n",
    "    \n",
    "    urlstring = 'http://www.basketball-reference.com/boxscores/pbp/'+thisgameid[0]+'.html'\n",
    "\n",
    "    source = urllib.request.urlopen(urlstring)\n",
    "    source = source.read()\n",
    "    soup = bs4.BeautifulSoup(source, 'lxml')\n",
    "    pbptable = soup.find('table',attrs={'class':'no_highlight stats_table'})\n",
    "    tdswFT = pbptable.findAll(['td','th'])\n",
    "\n",
    "    ftrows = [t.parent for t in tdswFT if ('free throw' in t.text or (t.has_attr('colspan') and t['colspan']=='6'))]\n",
    "\n",
    "    teama = pbptable.find('tr',attrs={'id':False}).contents[3].contents[0]\n",
    "    teamh = pbptable.find('tr',attrs={'id':False}).contents[7].contents[0]\n",
    "    \n",
    "    period = 0 #initialize which quarter is being played\n",
    "\n",
    "    for i,row in enumerate(ftrows):\n",
    "        if row.has_attr('id'):\n",
    "            period = period + 1\n",
    "        else:\n",
    "            gameid.append(thisgameid[0])\n",
    "            timeinperiod = row.contents[1].contents[0]\n",
    "            timeinperiod = float(timeinperiod.split(':')[0])+float(timeinperiod.split(':')[1])/60\n",
    "            if period<=4:\n",
    "                totaltime = 12.0*period-timeinperiod\n",
    "            else:\n",
    "                totaltime = 48.0+5.0*(period-4)-timeinperiod\n",
    "            gametime.append(round(totaltime,3))\n",
    "            home = row.contents[3].contents[0]=='\\xa0'\n",
    "            if home:\n",
    "                player.append(row.contents[7].find('a').contents[0])\n",
    "                playerid.append(row.contents[7].find('a')['href'].split('/')[-1].split('.')[0])\n",
    "                team.append(teamh)\n",
    "                opponent.append(teama)\n",
    "                teamha.append('H')\n",
    "                result.append(int('makes' in row.contents[7].text))\n",
    "                try:\n",
    "                    ftnumber.append(int(re.findall('\\d+', row.contents[7].text)[0]))\n",
    "                except:\n",
    "                    ftnumber.append(1) \n",
    "                if 'technical' in row.contents[7].text:\n",
    "                    tech.append(1)\n",
    "                else:\n",
    "                    tech.append(0)\n",
    "\n",
    "            else:\n",
    "                player.append(row.contents[3].find('a').contents[0])\n",
    "                playerid.append(row.contents[3].find('a')['href'].split('/')[-1].split('.')[0])\n",
    "                team.append(teama)\n",
    "                opponent.append(teamh)\n",
    "                teamha.append('A')\n",
    "                result.append(int('makes' in row.contents[3].text))\n",
    "                try:\n",
    "                    ftnumber.append(int(re.findall('\\d+', row.contents[3].text)[0]))\n",
    "                except:\n",
    "                    ftnumber.append(1)  \n",
    "                if 'technical' in row.contents[3].text:\n",
    "                    tech.append(1)\n",
    "                else:\n",
    "                    tech.append(0)\n",
    "                    \n",
    "            scores = row.contents[5].contents[0].split('-')\n",
    "            scorea.append(scores[0])\n",
    "            scoreh.append(scores[1])\n",
    "\n",
    "    data = {'gameid':gameid,'gametime':gametime,'player':player,'playerid':playerid,'team':team,'teamha':teamha,'opponent':opponent,'scorea':scorea,'scoreh':scoreh,'result':result,'ftnumber':ftnumber,'tech':tech}\n",
    "\n",
    "    oneGame = pd.DataFrame(data,columns=['gameid','gametime','player','playerid','team','teamha','opponent','scorea','scoreh','result','ftnumber','tech'])\n",
    "    oneGame.to_sql('pbpfts',engine,if_exists='append')\n",
    "\n",
    "    pbar2.increment()\n",
    "pbar2.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Year-to-date Percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important that we don't violate the flow of time so we should only be allowed to know the year-to-date free throw average of each player in order to use it as a parameter to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM pbpfts\"\n",
    "oldpbpfts = psql.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT playerid,result,season FROM pbpfts JOIN allgames on pbpfts.gameid=allgames.gameid\"\n",
    "ytd_avg_needs = psql.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ytd_avg = np.empty((2,ytd_avg_needs.shape[0]))\n",
    "\n",
    "for i in range(ytd_avg_needs.shape[0]):\n",
    "    ytd_avg_needs_temp = ytd_avg_needs.ix[max(0,i-100000):i]\n",
    "    rowsToCount = (ytd_avg_needs_temp.season==ytd_avg_needs_temp.ix[i].season).values & (ytd_avg_needs_temp.playerid==ytd_avg_needs_temp.ix[i].playerid).values\n",
    "    ytd_avg[0,i]= rowsToCount.sum()\n",
    "    ytd_avg[1,i]=(ytd_avg_needs_temp[rowsToCount].result).sum()\n",
    "\n",
    "ytd_additional_columns = pd.DataFrame(ytd_avg.transpose(), columns=['attempts_to_date','makes_to_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newpbpfts = oldpbpfts.join(ytd_additional_columns)\n",
    "newpbpfts['ytd_ftpct'] = newpbpfts.makes_to_date/newpbpfts.attempts_to_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Score Differential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score differential is always calculated as the free throw shooting team minus the opposing team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newpbpfts['score_diff'] = (newpbpfts.scorea.astype(int)-newpbpfts.scoreh.astype(int))*(((newpbpfts.teamha=='A').values)*2-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can go back to SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newpbpfts.to_sql('allpbpfts',engine,if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Season Totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last category of useful data from basketball-reference.com is player statistics by season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yearRange = range(1950,2016)\n",
    "pbar2 = ProgressBar.ProgressBar(len(yearRange), finestep=True)\n",
    "\n",
    "for j,season in enumerate(yearRange):\n",
    "    year = []\n",
    "    player = []\n",
    "    playerid = []\n",
    "    team = []\n",
    "    pos = []\n",
    "    age = []\n",
    "    ft = []\n",
    "    fta = []\n",
    "    ftpct = []\n",
    "    \n",
    "    urlstring = 'http://www.basketball-reference.com/leagues/NBA_'+str(season)+'_totals.html'\n",
    "\n",
    "    source = urllib.request.urlopen(urlstring)\n",
    "    source = source.read()\n",
    "    soup = bs4.BeautifulSoup(source, 'lxml')\n",
    "    totalstable = soup.find('table',attrs={'class':'sortable  stats_table'})\n",
    "    datarows = totalstable.findAll('tr',attrs={'class':'full_table'})\n",
    "\n",
    "    for i,row in enumerate(datarows):\n",
    "        year.append(season)\n",
    "        player.append(row.contents[3].text)\n",
    "        playerid.append(row.contents[3].find('a')['href'].split('/')[-1].split('.')[0])\n",
    "        pos.append(row.contents[5].text)\n",
    "        age.append(row.contents[7].text)\n",
    "        team.append(row.contents[9].text)\n",
    "        ft.append(row.contents[37].text)\n",
    "        fta.append(row.contents[39].text)\n",
    "        ftpct.append(row.contents[41].text)\n",
    "\n",
    "    data = {'year':year,'player':player,'playerid':playerid,'team':team,'pos':pos,'age':age,'ft':ft,'fta':fta,'ftpct':ftpct}\n",
    "\n",
    "    oneYear = pd.DataFrame(data,columns=['year','player','playerid','team','pos','age','ft','fta','ftpct'])\n",
    "    oneYear.to_sql('totals',engine,if_exists='append')\n",
    "\n",
    "    pbar2.increment()\n",
    "pbar2.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Career-to-date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM seasontotals\"\n",
    "allseasons = psql.read_sql(query,conn)\n",
    "newseasons = allseasons[allseasons.year.astype(int) >= 2002].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctd_fts = np.empty((3,newseasons.shape[0]))\n",
    "for i in range(newseasons.shape[0]):\n",
    "    rowsToCount = (allseasons.year.astype(int)<newseasons.ix[i].year.astype(int)).values & (allseasons.playerid==newseasons.ix[i].playerid).values\n",
    "    ctd_fts[0,i]= allseasons[rowsToCount].fta.astype(int).sum()\n",
    "    ctd_fts[1,i]=allseasons[rowsToCount].ft.astype(int).sum()\n",
    "    ctd_fts[2,i] = rowsToCount.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctd_columns = pd.DataFrame(ctd_fts.transpose(), columns=['ctd_fta','ctd_ft','years_in_league'])\n",
    "ctd_columns['ctd_ftpct'] = ctd_columns.ctd_ft.astype(int)/ctd_columns.ctd_fta.astype(int)\n",
    "\n",
    "newseasons = newseasons.join(ctd_columns)\n",
    "newseasons = newseasons.drop('level_0',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newseasons.to_sql('seasonwithcareer',engine,if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casting to Proper Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"ALTER TABLE seasonwithcareer ALTER COLUMN fta TYPE bigint USING fta::bigint\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"ALTER TABLE seasonwithcareer ALTER COLUMN ft TYPE bigint USING ft::bigint\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"ALTER TABLE seasonwithcareer ALTER COLUMN age TYPE bigint USING age::bigint\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"ALTER TABLE seasontotals ALTER COLUMN ft TYPE bigint USING ft::bigint\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"ALTER TABLE seasontotals ALTER COLUMN fta TYPE bigint USING fta::bigint\")\n",
    "conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
